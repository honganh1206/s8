# Lexical Analysis

- Goal: We change the *representation* of our source code **two times** before we evaluate it. (Side note: Graphs in ASCII are super neat!)

+-------------+         +------------+          +-----------+
|             |         |            |          |           |
|             |         |            |          |           |
| Source code +------- >| Token      +--------->|  AST      |
|             |         |            |          |           |
+-------------+         +------------+          +-----------+

- First transormation: Lexical analysis, done by a lexer/tokenizer/scanner - you name it!

- What are tokenizer? Small, categorizable data structures to be fed to the parser. After the first transformation, they turn into tokens and are fed to the AST.

- When we input this code `let x = 5 + 5` into the lexer, the output would be like this:

```
// This is passed into the lexer as an array
[
  LET,
  IDENTIFIER("x"),
  EQUALSIGN,
  INTEGER(5), // Concrete value it represents!
  PLUS_SIGN,
  INTEGER(5),
  SEMICOLON
]
```

- Lexer implementations differ in terms of *what exactly constitutes a "token"?*

- Whitespaces don't matter! They are just to separate tokens.
