# The Lexer

- Keep in mind: The lexer at this point will just accept the source code as the input and output the token that represents the source code. It will continue doing so until reaching the EOF.

- We will *repeatedly* call `NextToken()` when initializing our lexer. Note that in production we should attach filenames and line numbers to the token.

- A nice thing I notice when writing the lexer: Thorsten wrote the `lexer_test.go` BEFORE he wrote the `lexer.go`. A TDD guy!

- At this point our lexer is yet to support the full Unicode range because if so we need to change the type of `ch` from `byte` to `rune`

- We need to tell apart the user-defined identifiers and the language keywords. We also need to skip whitespaces that separate our tokens
